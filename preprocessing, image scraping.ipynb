{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "correct-cleaning",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "several-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import nltk\n",
    "import spacy\n",
    "import locationtagger\n",
    "from colorthief import ColorThief\n",
    "from geopy import geocoders, Nominatim\n",
    "import json\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "speaking-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "gn = Nominatim(user_agent=\"Your_Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-document",
   "metadata": {},
   "source": [
    "## Web scraping\n",
    "Retrieve the latest website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "executive-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the relevant website data, set an index, and put it into a dataframe\n",
    "url1 = 'http://en.wikipedia.org/wiki/List_of_works_by_Vincent_van_Gogh'\n",
    "tables = pd.read_html(url1)\n",
    "phases = tables[1:7]\n",
    "\n",
    "for i, ph in enumerate(phases):\n",
    "    phases[i] = ph.drop(['#', 'Image', 'Medium,Dimensions', 'Catalogue No.'], axis=1)\n",
    "vgph = pd.concat(phases)\n",
    "\n",
    "vgph.index = range(len(vgph))\n",
    "\n",
    "# Set workbook\n",
    "vgph1 = vgph.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-tuning",
   "metadata": {},
   "source": [
    "## Pre-processing\n",
    "Map the dates to seasons and extract the cities in which the works are currently located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "synthetic-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish patterns to search for in pre-processing\n",
    "#    Month data\n",
    "months_mapping = ['January', 'February', 'March',\n",
    "         'April', 'May', 'June', 'July',\n",
    "         'August', 'September', 'October',\n",
    "         'November', 'December', 'Spring',\n",
    "         'Summer', 'Autumn', 'Winter']\n",
    "month_pattern = '|'.join(months_mapping)\n",
    "\n",
    "#    Ownership data\n",
    "owner_pattern = ['Private', 'Private Collection', 'Private Collections',\n",
    "                    'Unknown', 'Stolen', 'Location']\n",
    "ownership_pattern = '|'.join(owner_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blond-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to map 'Date' to seasons\n",
    "def seasonal_search(search_str:str, search_list:str):\n",
    "    search_obj = re.search(search_list, search_str)\n",
    "    if search_obj:\n",
    "        return_str = search_str[search_obj.start():search_obj.end()]\n",
    "    else: \n",
    "        return_str = ''\n",
    "    return return_str\n",
    "\n",
    "def season_map(month):\n",
    "    if month == 'March' or month == 'April' or month == 'May' or month == 'Spring':\n",
    "        return 'Spring'\n",
    "    if month == 'June' or month == 'July' or month == 'August' or month == 'Summer':\n",
    "        return 'Summer'\n",
    "    if month == 'September' or month == 'October' or month == 'November' or month == 'Autumn':\n",
    "        return 'Autumn'\n",
    "    if month == 'December' or month == 'January' or month == 'February' or month == 'Winter': \n",
    "        return 'Winter'\n",
    "    \n",
    "# Helper function to map 'Current location' to an ownership pattern\n",
    "def ownership_search(search_str:str, search_list:str):\n",
    "    search_obj = re.search(search_list, search_str)\n",
    "    if search_obj:\n",
    "        return_str = search_str[search_obj.start():search_obj.end()]\n",
    "    else: \n",
    "        return_str = 'Museum'\n",
    "    return return_str\n",
    "\n",
    "# Helper function to retrieve the stripped citynames\n",
    "def loc_map(loc):\n",
    "    if loc == 'Villa':\n",
    "        return 'Winterthur'\n",
    "    if loc == 'Clark':\n",
    "        return 'Williamstown'\n",
    "    else:\n",
    "        return loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "historic-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "#     Correct for date/time information\n",
    "vgph1['Year'] = vgph1['Date']\n",
    "vgph1['Year'] = vgph1['Year'].str.replace(r'\\D', '', regex=True)\n",
    "vgph1['Year'] = vgph1['Year'].map(str).apply(lambda val: val[:4] if val[:2]=='18' else val[-4:])\n",
    "vgph1['Month'] = vgph1['Date'].str.replace(r'\\d+', '', regex=True).replace('\\W+','', regex=True)\n",
    "vgph1['Month'] = vgph1['Month'].apply(lambda x: seasonal_search(search_str=x, search_list=month_pattern))\n",
    "\n",
    "#     Draw 'Season' from 'Month'\n",
    "vgph1['Season'] = vgph1['Month'].apply(lambda x: season_map(x))\n",
    "\n",
    "#    Draw ownership from 'Current Location'\n",
    "vgph1['Ownership'] = vgph1['Current location'].apply(lambda x: ownership_search(search_str=x, search_list=ownership_pattern))\n",
    "\n",
    "#     Draw 'Place_Name' from 'Current Location' (time-consuming: run only once and store in separate .csv)\n",
    "# df_temp = pd.DataFrame()\n",
    "# df_temp2 = pd.DataFrame()\n",
    "# df_temp['Extracted location'] = vgph1['Current location'].apply(lambda x: locationtagger.find_locations(text = x))\n",
    "# df_temp['Tagged city'] = df_temp['Extracted location'].apply(lambda x: x.cities).astype(str)\n",
    "# df_temp['Tagged city'] = df_temp['Tagged city'].str.replace('[','', regex=True).replace(']','', regex=True).replace('Van','', regex=True).replace(\"'\", '', regex=True)\n",
    "# df_temp2 = df_temp['Tagged city'].str.split(',', expand=True)\n",
    "# vgph1['Current city'] = df_temp2[0].apply(lambda x: loc_map(x))\n",
    "\n",
    "#    Retrieve latitude and longitude from city names (time-consuming: run only once and store in separate .csv)\n",
    "# latitude, longitude = [], []\n",
    "# for loc in vgph1['Current city']:\n",
    "#     if (loc==''):\n",
    "#         latitude.append('')\n",
    "#         longitude.append('')\n",
    "#     else:\n",
    "#         location = gn.geocode(loc)\n",
    "#         latitude.append(location.latitude)\n",
    "#         longitude.append(location.longitude)\n",
    "\n",
    "# vgph1['Current x'] = latitude\n",
    "# vgph1['Current y'] = longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-mattress",
   "metadata": {},
   "source": [
    "## Image scraping\n",
    "Scrape images and infromation from the website and run the color classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "classified-shirt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the title and url of the images with BeautifulSoup \n",
    "img_titles = []\n",
    "img_urls = []\n",
    "    \n",
    "r = requests.get('http://en.wikipedia.org/wiki/List_of_works_by_Vincent_van_Gogh') \n",
    "soup = BeautifulSoup(r.text, 'html.parser') \n",
    "\n",
    "for item in soup.find_all('img'):\n",
    "    img_titles.append(item['alt'])\n",
    "    img_urls.append('https:' + item['src'])\n",
    "    \n",
    "# Add the file name and url to the dataframe\n",
    "# Omit the first img featured (Vincent van Gogh portrait)\n",
    "vgph1['.jpg name'] = img_titles[1:len(vgph1)+1]\n",
    "vgph1['.jpg url'] = img_urls[1:len(vgph1)+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "radio-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images and store in local folder (time-consuming: run only once and store in separate .csv)\n",
    "\n",
    "# def imagedown(df, url, folder):\n",
    "    \n",
    "#     try:\n",
    "#         os.mkdir(os.path.join(os.getcwd(), folder))\n",
    "#     except:\n",
    "#         pass\n",
    "#     os.chdir(os.path.join(os.getcwd(), folder))\n",
    "    \n",
    "#     r = requests.get(url)\n",
    "#     soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#     images = soup.find_all('img')\n",
    "#     images_lic = images[1:len(df)+1]\n",
    "    \n",
    "#     for i, image in enumerate(images_lic):\n",
    "#         name = image['alt']\n",
    "#         link = 'https:' + image['src']\n",
    "#         index = 'vg{:0>3}_'.format(i)\n",
    "#         with open(index + name.replace('jpeg', '').replace('JPG', '').replace('jpg', '').replace('\"', '').replace('?', '').replace(':', '-').replace('*', '').replace('<', '').replace('>', '').replace('|', '-').replace('/', '-').replace('(', '-').replace(')', '-').replace(' ', '-') + 'jpg', 'wb') as f:\n",
    "#             im = requests.get(link, headers={'Host': 'upload.wikimedia.org'})\n",
    "#             f.write(im.content)\n",
    "\n",
    "# imagedown(vgph1, 'http://en.wikipedia.org/wiki/List_of_works_by_Vincent_van_Gogh', 'van_gogh_paintings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manufactured-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to retrieve and save dominant colors and color palette from the paintings\n",
    "def colorscrape(df, directory):\n",
    "    dominant_r, dominant_g, dominant_b, dominant_rgb, palette = [], [], [], [], []\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        f = os.path.join(directory, filename)\n",
    "        if os.path.isfile(f):\n",
    "            color_thief = ColorThief(f)\n",
    "            dominant_color= color_thief.get_color(quality=3)\n",
    "            dominant_r.append(dominant_color[0])\n",
    "            dominant_g.append(dominant_color[1])\n",
    "            dominant_b.append(dominant_color[2])\n",
    "            dominant_rgb.append(dominant_color)\n",
    "            palette.append(color_thief.get_palette(color_count = 5))\n",
    "    \n",
    "    df['R'] = dominant_r\n",
    "    df['G'] = dominant_g\n",
    "    df['B'] = dominant_b\n",
    "    df['Dominant Color'] = dominant_rgb\n",
    "    df['Color Palette'] = palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "theoretical-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve colors and color palette from local folder (time-consuming: run only once and store in separate .csv)\n",
    "#colorscrape(vgph1, r'C:\\Users\\s164386\\VolVis\\epds\\life_in_color\\van_gogh_paintings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "solid-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the time-consuming code for a faster website (last update: 14/01/2022)\n",
    "\n",
    "#vg_place_color = vgph2[['Current city', 'Current x', 'Current y', '.jpg name', '.jpg url', 'Dominant Color', 'Color Palette', 'R', 'G', 'B', 'HLS', 'H', 'L', 'S']]\n",
    "#vg_place_color.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\life_in_color\\datasets\\vg_place_color.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-middle",
   "metadata": {},
   "source": [
    "## Dataset configuration\n",
    "Join live data with pre-classified data (city, color) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "wanted-position",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The WikiPedia table might have been manipulated.\n",
      "It seems that some of his paintings have been removed from the Wikipedia page.\n",
      "The number of artworks that were downloaded and colorcoded: 870\n",
      "The number of artworks that are currently featured on the WikiPedia page: 868\n"
     ]
    }
   ],
   "source": [
    "# Load local data and check for changes\n",
    "vg_place_color =  pd.read_csv('https://raw.githubusercontent.com/wieswies/lifeincolor/main/data/vg_place_color.csv')\n",
    "if len(vg_place_color)!=len(vgph1):\n",
    "    print(\"The WikiPedia table might have been manipulated.\")\n",
    "    if len(vg_place_color)< len(vgph1):\n",
    "        print(\"It seems that some of his paintings have been added to the Wikipedia page.\")\n",
    "    if len(vg_place_color)> len(vgph1):\n",
    "        print(\"It seems that some of his paintings have been removed from the Wikipedia page.\")\n",
    "print(\"The number of artworks that were downloaded and colorcoded: \" + str(len(vg_place_color)))\n",
    "print(\"The number of artworks that are currently featured on the WikiPedia page: \" + str(len(vgph1)))\n",
    "\n",
    "# Configure dataset with an inner join to ensure correctness of colormapping and live-data\n",
    "vgph2 = pd.merge(vgph1, vg_place_color)\n",
    "\n",
    "# Back-up csv\n",
    "vgph2.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\vg_data.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-tension",
   "metadata": {},
   "source": [
    "## Workcount statistics\n",
    "Retrieve relevant statistics about the artist's life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "western-hampton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 635 out of 868 artworks, the season in which they were made is known.\n"
     ]
    }
   ],
   "source": [
    "# Extract from how many works the season can be determined\n",
    "vgph_temp = vgph1.dropna(subset=['Season'])\n",
    "print(\"From \" + str(vgph_temp.shape[0]) + \" out of \" + str(vgph1.shape[0]) + \" artworks, the season in which they were made is known.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acute-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare .csv for d3 stacked barchart about seasonality\n",
    "vgph_temp2 = pd.DataFrame({'Count': vgph_temp.groupby( ['Created in', 'Season'], dropna=False).size()}).reset_index()\n",
    "vgph_barchart = pd.DataFrame()\n",
    "vgph_barchart['place'] = [place for place in vgph1['Created in'].unique()]\n",
    "\n",
    "autumn, winter, spring, summer = np.zeros(len(vgph_barchart)), np.zeros(len(vgph_barchart)), np.zeros(len(vgph_barchart)), np.zeros(len(vgph_barchart))\n",
    "\n",
    "for index, place in enumerate(vgph_barchart['place']):\n",
    "    for i, row in vgph_temp2.iterrows():\n",
    "        if row['Created in']==place:\n",
    "            if row['Season']==\"Autumn\":\n",
    "                    autumn[index] = row['Count']\n",
    "            if row['Season']==\"Winter\":\n",
    "                    winter[index] = row['Count']\n",
    "            if row['Season']==\"Spring\":\n",
    "                    spring[index] = row['Count']\n",
    "            if row['Season']==\"Summer\":\n",
    "                    summer[index] = row['Count']\n",
    "vgph_barchart['autumn'] = autumn\n",
    "vgph_barchart['winter'] = winter\n",
    "vgph_barchart['spring'] = spring\n",
    "vgph_barchart['summer'] = summer\n",
    "vgph_barchart.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\statistics\\vgph_barchart.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "underlying-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare .csv for d3 barchart about yearly productivity\n",
    "vgph_temp3 = pd.DataFrame({'count': vgph2.groupby(['Year'], dropna=False).size()}).reset_index()\n",
    "vgph_temp3.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\statistics\\barchart_year.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-bubble",
   "metadata": {},
   "source": [
    "## Color gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "saved-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the array to draw the gradient - group colors by 'Created in'\n",
    "# Read retrieved colors and initialize arrays\n",
    "colormap_thehague = []\n",
    "colormap_amsterdam = []\n",
    "colormap_drenthe = []\n",
    "colormap_nuenen = []\n",
    "colormap_antwerp = []\n",
    "colormap_paris = []\n",
    "colormap_arles = []\n",
    "colormap_saintremy = []\n",
    "colormap_auverssuroise = []\n",
    "\n",
    "# Store the colors in grouped arrays\n",
    "for index, row in vgph2.iterrows():\n",
    "    if (row['Created in'] == \"The Hague\"):\n",
    "        colormap_thehague.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Scheveningen\"):\n",
    "        colormap_thehague.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Amsterdam\"):\n",
    "        colormap_amsterdam.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Nieuw-Amsterdam\"):\n",
    "        colormap_amsterdam.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Drenthe\"):\n",
    "        colormap_drenthe.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Nuenen\"):\n",
    "        colormap_nuenen.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Antwerp\"):\n",
    "        colormap_antwerp.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Paris\"):\n",
    "        colormap_paris.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Arles\"):\n",
    "        colormap_arles.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Saint-Rémy\"):\n",
    "        colormap_saintremy.append(\"rgb\"+row['Dominant Color'])\n",
    "    if (row['Created in'] == \"Auvers-sur-Oise\"):\n",
    "        colormap_auverssuroise.append(\"rgb\"+row['Dominant Color'])\n",
    "        \n",
    "# Write the .txt files to feature them in .css\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_thehague.txt', \"w\") as txt_file:\n",
    "    for line in colormap_thehague:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_amsterdam.txt', \"w\") as txt_file:\n",
    "    for line in colormap_amsterdam:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_drenthe.txt', \"w\") as txt_file:\n",
    "    for line in colormap_drenthe:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_nuenen.txt', \"w\") as txt_file:\n",
    "    for line in colormap_nuenen:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_antwerp.txt', \"w\") as txt_file:\n",
    "    for line in colormap_antwerp:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_paris.txt', \"w\") as txt_file:\n",
    "    for line in colormap_paris:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_arles.txt', \"w\") as txt_file:\n",
    "    for line in colormap_arles:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_saintremy.txt', \"w\") as txt_file:\n",
    "    for line in colormap_saintremy:\n",
    "        txt_file.write(\"\".join(line) + \",\")\n",
    "with open(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\colormaps\\cm_auverssuroise.txt', \"w\") as txt_file:\n",
    "    for line in colormap_auverssuroise:\n",
    "        txt_file.write(\"\".join(line) + \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-collector",
   "metadata": {},
   "source": [
    "## Connection coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "expressed-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about Van Gogh's living pattern, retrieved from Van Gogh Museum website (time-consuming: run only once and store in separate .csv)\n",
    "vg_places = [\"Zundert\", \"Zevenbergen\", \"Tilburg\",\n",
    "            \"The Hague\", \"London\", \"Paris\", \"Dordrecht\",\n",
    "            \"Amsterdam\", \"Borinage\", \"Brussels\", \"Etten\",\n",
    "            \"The Hague\", \"Drenthe\", \"Nuenen\", \"Antwerp\",\n",
    "            \"Paris\", \"Arles\", \"Saint-Remy\", \"Auvers-sur-Oise\"]\n",
    "\n",
    "# vg_lat, vg_lon = [], []\n",
    "# for place in vg_places:\n",
    "#     location = gn.geocode(place)\n",
    "#     vg_lat.append(location.latitude)\n",
    "#     vg_lon.append(location.longitude)\n",
    "\n",
    "# vg_locations = pd.DataFrame()\n",
    "# vg_locations['place'] = vg_places\n",
    "# vg_locations['lat'] = vg_lat\n",
    "# vg_locations['lon'] = vg_lon\n",
    "# vg_locations.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\map\\vg_latlon_names.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "elementary-elder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare .csv for connection map\n",
    "# vg_latlon = pd.DataFrame()\n",
    "# vg_lat1 = vg_lat[:len(vg_lat)-1]\n",
    "# vg_lat2 = vg_lat[1:]\n",
    "# vg_lon1 = vg_lon[:len(vg_lon)-1]\n",
    "# vg_lon2 = vg_lon[1:]\n",
    "# vg_latlon['long1'] = vg_lon1\n",
    "# vg_latlon['long2'] = vg_lon2\n",
    "# vg_latlon['lat1'] = vg_lat1\n",
    "# vg_latlon['lat2'] = vg_lat2\n",
    "# vg_latlon.to_csv(r'C:\\Users\\s164386\\VolVis\\epds\\lifeincolor\\data\\map\\vg_latlon.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
